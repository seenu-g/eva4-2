{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilevnet2 transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JxmMsu0wldmBUHldbywSt4clHhJeYCDl",
      "authorship_tag": "ABX9TyNSqZ50Txf8bnw4dU6KKauC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad6779400f4047118df51528f415cd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e687dbf18064ea18ec2eccffe57b4c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c75e6f18a7f942f4bf6927481ec0c13d",
              "IPY_MODEL_3cadcaa2e03d444a9428fd7fa2d4062b"
            ]
          }
        },
        "6e687dbf18064ea18ec2eccffe57b4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c75e6f18a7f942f4bf6927481ec0c13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4e1e076c8d444fab203e29de9faea3a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14196051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14196051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bb9b5f23cb84dc395f3aa8eeafe46cc"
          }
        },
        "3cadcaa2e03d444a9428fd7fa2d4062b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32b2e35e2c9b43758cd8a40fdaa7a5ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13.5M/13.5M [01:58&lt;00:00, 120kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2811e3d0a9b4f718950b0f8c599a5dd"
          }
        },
        "c4e1e076c8d444fab203e29de9faea3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bb9b5f23cb84dc395f3aa8eeafe46cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32b2e35e2c9b43758cd8a40fdaa7a5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2811e3d0a9b4f718950b0f8c599a5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seenu-g/eva4-2/blob/master/week2/mobilevnet2_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM0HgkN8BYoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a06f7c4-44c9-46ae-dba7-e82ba4028fd8"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.5.1+cu101\n",
            "Torchvision Version:  0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6jQSxwjCWYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e098a3dd-b07f-4dbc-fd0a-bb361552a689"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA83lq_NH294",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "714ead52-3d65-4cd1-bac7-2e3da71589b5"
      },
      "source": [
        "cd '/content/gdrive/My Drive/school_of_ai/eva4-2/week2'\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/school_of_ai/eva4-2/week2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0c6Vu15B_1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_folder = '//content/gdrive/My Drive/school_of_ai/eva4-2/week2/'\n",
        "\n",
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = raw_folder + \"hymenoptera_data\"\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"squeezenet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ux6IBMqGelY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3_oAom1GqLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpOa-ddhp5Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "def conv_bn(inp, oup, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.ReLU6(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_1x1_bn(inp, oup):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.ReLU6(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def make_divisible(x, divisible_by=8):\n",
        "    import numpy as np\n",
        "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = int(inp * expand_ratio)\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        if expand_ratio == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        block = InvertedResidual\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "        interverted_residual_setting = [\n",
        "            # t, c, n, s\n",
        "            [1, 16, 1, 1],\n",
        "            [6, 24, 2, 2],\n",
        "            [6, 32, 3, 2],\n",
        "            [6, 64, 4, 2],\n",
        "            [6, 96, 3, 1],\n",
        "            [6, 160, 3, 2],\n",
        "            [6, 320, 1, 1],\n",
        "        ]\n",
        "\n",
        "        # building first layer\n",
        "        assert input_size % 32 == 0\n",
        "        # input_channel = make_divisible(input_channel * width_mult)  # first channel is always 32!\n",
        "        self.last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
        "        self.features = [conv_bn(3, input_channel, 2)]\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in interverted_residual_setting:\n",
        "            output_channel = make_divisible(c * width_mult) if t > 1 else c\n",
        "            for i in range(n):\n",
        "                if i == 0:\n",
        "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
        "                else:\n",
        "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Linear(self.last_channel, n_class)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.mean(3).mean(2)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                n = m.weight.size(1)\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcMQMLhBqID_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mobilenet_v2(pretrained=True):\n",
        "    model = MobileNetV2(width_mult=1)\n",
        "    \n",
        "    if pretrained:\n",
        "        try:\n",
        "            from torch.hub import load_state_dict_from_url\n",
        "        except ImportError:\n",
        "            from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "        state_dict = load_state_dict_from_url(\n",
        "            'https://www.dropbox.com/s/47tyzpofuuyyv1b/mobilenetv2_1.0-f2a8633.pth.tar?dl=1', progress=True)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSc6sArHG-V7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "19fa871a-e5f5-4c8a-a422-0f1a7ae9ff59"
      },
      "source": [
        "input_size = 224\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "print(len(image_datasets['train']))\n",
        "print(len(image_datasets['val']))\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "raw_train_dataiter = iter(dataloaders_dict['train'])\n",
        "val_train_dataiter = iter(dataloaders_dict['val'])\n",
        "\n",
        "train_images = raw_train_dataiter.next()\n",
        "val_images = val_train_dataiter.next()\n",
        "print(train_images[0].shape)\n",
        "print(val_images[0].shape)\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n",
            "244\n",
            "153\n",
            "torch.Size([8, 3, 224, 224])\n",
            "torch.Size([8, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKsCJEfhjBHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ad6779400f4047118df51528f415cd4e",
            "6e687dbf18064ea18ec2eccffe57b4c9",
            "c75e6f18a7f942f4bf6927481ec0c13d",
            "3cadcaa2e03d444a9428fd7fa2d4062b",
            "c4e1e076c8d444fab203e29de9faea3a",
            "2bb9b5f23cb84dc395f3aa8eeafe46cc",
            "32b2e35e2c9b43758cd8a40fdaa7a5ef",
            "d2811e3d0a9b4f718950b0f8c599a5dd"
          ]
        },
        "outputId": "b920eccd-73c3-4c59-eae7-f07288bef412"
      },
      "source": [
        "model_ft = mobilenet_v2()\n",
        "print(model_ft)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://www.dropbox.com/s/47tyzpofuuyyv1b/mobilenetv2_1.0-f2a8633.pth.tar?dl=1\" to /root/.cache/torch/checkpoints/mobilenetv2_1.0-f2a8633.pth.tar\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad6779400f4047118df51528f415cd4e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14196051.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MobileNetV2(\n",
            "  (features): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (16): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (17): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU6(inplace=True)\n",
            "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (18): Sequential(\n",
            "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSp-04rNHDb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f03bd202-1d72-4630-d71f-7bed09203095"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "# Observe that all parameters are being optimized\n",
        "#inception\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t features.0.0.weight\n",
            "\t features.0.1.weight\n",
            "\t features.0.1.bias\n",
            "\t features.1.conv.0.weight\n",
            "\t features.1.conv.1.weight\n",
            "\t features.1.conv.1.bias\n",
            "\t features.1.conv.3.weight\n",
            "\t features.1.conv.4.weight\n",
            "\t features.1.conv.4.bias\n",
            "\t features.2.conv.0.weight\n",
            "\t features.2.conv.1.weight\n",
            "\t features.2.conv.1.bias\n",
            "\t features.2.conv.3.weight\n",
            "\t features.2.conv.4.weight\n",
            "\t features.2.conv.4.bias\n",
            "\t features.2.conv.6.weight\n",
            "\t features.2.conv.7.weight\n",
            "\t features.2.conv.7.bias\n",
            "\t features.3.conv.0.weight\n",
            "\t features.3.conv.1.weight\n",
            "\t features.3.conv.1.bias\n",
            "\t features.3.conv.3.weight\n",
            "\t features.3.conv.4.weight\n",
            "\t features.3.conv.4.bias\n",
            "\t features.3.conv.6.weight\n",
            "\t features.3.conv.7.weight\n",
            "\t features.3.conv.7.bias\n",
            "\t features.4.conv.0.weight\n",
            "\t features.4.conv.1.weight\n",
            "\t features.4.conv.1.bias\n",
            "\t features.4.conv.3.weight\n",
            "\t features.4.conv.4.weight\n",
            "\t features.4.conv.4.bias\n",
            "\t features.4.conv.6.weight\n",
            "\t features.4.conv.7.weight\n",
            "\t features.4.conv.7.bias\n",
            "\t features.5.conv.0.weight\n",
            "\t features.5.conv.1.weight\n",
            "\t features.5.conv.1.bias\n",
            "\t features.5.conv.3.weight\n",
            "\t features.5.conv.4.weight\n",
            "\t features.5.conv.4.bias\n",
            "\t features.5.conv.6.weight\n",
            "\t features.5.conv.7.weight\n",
            "\t features.5.conv.7.bias\n",
            "\t features.6.conv.0.weight\n",
            "\t features.6.conv.1.weight\n",
            "\t features.6.conv.1.bias\n",
            "\t features.6.conv.3.weight\n",
            "\t features.6.conv.4.weight\n",
            "\t features.6.conv.4.bias\n",
            "\t features.6.conv.6.weight\n",
            "\t features.6.conv.7.weight\n",
            "\t features.6.conv.7.bias\n",
            "\t features.7.conv.0.weight\n",
            "\t features.7.conv.1.weight\n",
            "\t features.7.conv.1.bias\n",
            "\t features.7.conv.3.weight\n",
            "\t features.7.conv.4.weight\n",
            "\t features.7.conv.4.bias\n",
            "\t features.7.conv.6.weight\n",
            "\t features.7.conv.7.weight\n",
            "\t features.7.conv.7.bias\n",
            "\t features.8.conv.0.weight\n",
            "\t features.8.conv.1.weight\n",
            "\t features.8.conv.1.bias\n",
            "\t features.8.conv.3.weight\n",
            "\t features.8.conv.4.weight\n",
            "\t features.8.conv.4.bias\n",
            "\t features.8.conv.6.weight\n",
            "\t features.8.conv.7.weight\n",
            "\t features.8.conv.7.bias\n",
            "\t features.9.conv.0.weight\n",
            "\t features.9.conv.1.weight\n",
            "\t features.9.conv.1.bias\n",
            "\t features.9.conv.3.weight\n",
            "\t features.9.conv.4.weight\n",
            "\t features.9.conv.4.bias\n",
            "\t features.9.conv.6.weight\n",
            "\t features.9.conv.7.weight\n",
            "\t features.9.conv.7.bias\n",
            "\t features.10.conv.0.weight\n",
            "\t features.10.conv.1.weight\n",
            "\t features.10.conv.1.bias\n",
            "\t features.10.conv.3.weight\n",
            "\t features.10.conv.4.weight\n",
            "\t features.10.conv.4.bias\n",
            "\t features.10.conv.6.weight\n",
            "\t features.10.conv.7.weight\n",
            "\t features.10.conv.7.bias\n",
            "\t features.11.conv.0.weight\n",
            "\t features.11.conv.1.weight\n",
            "\t features.11.conv.1.bias\n",
            "\t features.11.conv.3.weight\n",
            "\t features.11.conv.4.weight\n",
            "\t features.11.conv.4.bias\n",
            "\t features.11.conv.6.weight\n",
            "\t features.11.conv.7.weight\n",
            "\t features.11.conv.7.bias\n",
            "\t features.12.conv.0.weight\n",
            "\t features.12.conv.1.weight\n",
            "\t features.12.conv.1.bias\n",
            "\t features.12.conv.3.weight\n",
            "\t features.12.conv.4.weight\n",
            "\t features.12.conv.4.bias\n",
            "\t features.12.conv.6.weight\n",
            "\t features.12.conv.7.weight\n",
            "\t features.12.conv.7.bias\n",
            "\t features.13.conv.0.weight\n",
            "\t features.13.conv.1.weight\n",
            "\t features.13.conv.1.bias\n",
            "\t features.13.conv.3.weight\n",
            "\t features.13.conv.4.weight\n",
            "\t features.13.conv.4.bias\n",
            "\t features.13.conv.6.weight\n",
            "\t features.13.conv.7.weight\n",
            "\t features.13.conv.7.bias\n",
            "\t features.14.conv.0.weight\n",
            "\t features.14.conv.1.weight\n",
            "\t features.14.conv.1.bias\n",
            "\t features.14.conv.3.weight\n",
            "\t features.14.conv.4.weight\n",
            "\t features.14.conv.4.bias\n",
            "\t features.14.conv.6.weight\n",
            "\t features.14.conv.7.weight\n",
            "\t features.14.conv.7.bias\n",
            "\t features.15.conv.0.weight\n",
            "\t features.15.conv.1.weight\n",
            "\t features.15.conv.1.bias\n",
            "\t features.15.conv.3.weight\n",
            "\t features.15.conv.4.weight\n",
            "\t features.15.conv.4.bias\n",
            "\t features.15.conv.6.weight\n",
            "\t features.15.conv.7.weight\n",
            "\t features.15.conv.7.bias\n",
            "\t features.16.conv.0.weight\n",
            "\t features.16.conv.1.weight\n",
            "\t features.16.conv.1.bias\n",
            "\t features.16.conv.3.weight\n",
            "\t features.16.conv.4.weight\n",
            "\t features.16.conv.4.bias\n",
            "\t features.16.conv.6.weight\n",
            "\t features.16.conv.7.weight\n",
            "\t features.16.conv.7.bias\n",
            "\t features.17.conv.0.weight\n",
            "\t features.17.conv.1.weight\n",
            "\t features.17.conv.1.bias\n",
            "\t features.17.conv.3.weight\n",
            "\t features.17.conv.4.weight\n",
            "\t features.17.conv.4.bias\n",
            "\t features.17.conv.6.weight\n",
            "\t features.17.conv.7.weight\n",
            "\t features.17.conv.7.bias\n",
            "\t features.18.0.weight\n",
            "\t features.18.1.weight\n",
            "\t features.18.1.bias\n",
            "\t classifier.weight\n",
            "\t classifier.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-i2-H3CHIZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81b6b442-3a88-43a2-f32e-332be8f9ca8a"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 3.0516 Acc: 0.5779\n",
            "val Loss: 1.2544 Acc: 0.7582\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.8330 Acc: 0.7869\n",
            "val Loss: 0.6440 Acc: 0.8693\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.6352 Acc: 0.8238\n",
            "val Loss: 0.4011 Acc: 0.8627\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.7638 Acc: 0.7582\n",
            "val Loss: 0.4670 Acc: 0.8301\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.2913 Acc: 0.8689\n",
            "val Loss: 0.3201 Acc: 0.8693\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.2532 Acc: 0.9098\n",
            "val Loss: 0.4293 Acc: 0.8627\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3494 Acc: 0.8689\n",
            "val Loss: 0.3567 Acc: 0.8824\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.2300 Acc: 0.8934\n",
            "val Loss: 0.3968 Acc: 0.8562\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.4223 Acc: 0.8484\n",
            "val Loss: 0.3864 Acc: 0.8954\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.4533 Acc: 0.8484\n",
            "val Loss: 0.3741 Acc: 0.8693\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.3730 Acc: 0.8566\n",
            "val Loss: 0.4353 Acc: 0.8562\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.2403 Acc: 0.8893\n",
            "val Loss: 0.3121 Acc: 0.8693\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.2938 Acc: 0.8770\n",
            "val Loss: 0.2564 Acc: 0.9150\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.2495 Acc: 0.8852\n",
            "val Loss: 0.5466 Acc: 0.8497\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.2693 Acc: 0.9098\n",
            "val Loss: 0.3374 Acc: 0.8824\n",
            "\n",
            "Training complete in 1m 53s\n",
            "Best val Acc: 0.915033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZJ--yiRHO1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "768c1ce4-9262-44cf-d365-e3b84e0873b3"
      },
      "source": [
        "# Initialize the non-pretrained version of the model used for this run\n",
        "scratch_model = mobilenet_v2(pretrained=False)\n",
        "scratch_model = scratch_model.to(device)\n",
        "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
        "scratch_criterion = nn.CrossEntropyLoss()\n",
        "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs)\n",
        "\n",
        "# Plot the training curves of validation accuracy vs. number\n",
        "#  of training epochs for the transfer learning method and\n",
        "#  the model trained from scratch\n",
        "ohist = []\n",
        "shist = []\n",
        "\n",
        "ohist = [h.cpu().numpy() for h in hist]\n",
        "shist = [h.cpu().numpy() for h in scratch_hist]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
        "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 2.6037 Acc: 0.4713\n",
            "val Loss: 1.0859 Acc: 0.4575\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.7120 Acc: 0.5287\n",
            "val Loss: 0.9959 Acc: 0.4575\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.6846 Acc: 0.5779\n",
            "val Loss: 0.7679 Acc: 0.6209\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.7091 Acc: 0.5369\n",
            "val Loss: 0.6929 Acc: 0.5425\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.7040 Acc: 0.5574\n",
            "val Loss: 0.6573 Acc: 0.6340\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.6817 Acc: 0.5820\n",
            "val Loss: 0.6482 Acc: 0.6209\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.6729 Acc: 0.6025\n",
            "val Loss: 0.6055 Acc: 0.6993\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.6681 Acc: 0.6025\n",
            "val Loss: 0.6271 Acc: 0.6601\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.6843 Acc: 0.5902\n",
            "val Loss: 0.6604 Acc: 0.5817\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.6141 Acc: 0.6721\n",
            "val Loss: 0.7161 Acc: 0.6340\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.5959 Acc: 0.6721\n",
            "val Loss: 0.8803 Acc: 0.6536\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.6529 Acc: 0.6557\n",
            "val Loss: 0.6356 Acc: 0.6275\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.5764 Acc: 0.7090\n",
            "val Loss: 0.6468 Acc: 0.6732\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.6139 Acc: 0.6885\n",
            "val Loss: 0.6881 Acc: 0.6732\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.6357 Acc: 0.6598\n",
            "val Loss: 0.7325 Acc: 0.5621\n",
            "\n",
            "Training complete in 1m 17s\n",
            "Best val Acc: 0.699346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JxmMsu0wldmBUHldbywSt4clHhJeYCDl",
      "authorship_tag": "ABX9TyPlpFP6fKEtlxujmRE5fvm3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0febde1290944799d7e67f541ab1687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ddf185cb87b42c4ace57d9213b14275",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf3f45bfca53459cad3800ee7e7a0845",
              "IPY_MODEL_df25a1746ed3408f9d023f542c77f8bd"
            ]
          }
        },
        "8ddf185cb87b42c4ace57d9213b14275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf3f45bfca53459cad3800ee7e7a0845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6efa8cec8b44631b96e89fef9e07cb4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5017600,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5017600,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6a81007195e433bb345fa7c9785832e"
          }
        },
        "df25a1746ed3408f9d023f542c77f8bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77e71df6af6b4ea2af49dca80830a917",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.79M/4.79M [02:03&lt;00:00, 40.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cb13cbfad7545508fafa2dae8e80e6c"
          }
        },
        "e6efa8cec8b44631b96e89fef9e07cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6a81007195e433bb345fa7c9785832e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77e71df6af6b4ea2af49dca80830a917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cb13cbfad7545508fafa2dae8e80e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seenu-g/eva4-2/blob/master/week2/experiment/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM0HgkN8BYoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48d3782d-c8b8-4afa-d511-527571435686"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.5.1+cu101\n",
            "Torchvision Version:  0.6.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6jQSxwjCWYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8a2a3cd1-3bb4-4429-f62b-2fec3730f191"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA83lq_NH294",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bda6481-4934-4a68-cab3-412eaf265f35"
      },
      "source": [
        "cd '/content/gdrive/My Drive/school_of_ai/eva4-2/week2'\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/school_of_ai/eva4-2/week2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0c6Vu15B_1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_folder = '//content/gdrive/My Drive/school_of_ai/eva4-2/week2/'\n",
        "\n",
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = raw_folder + \"hymenoptera_data\"\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"squeezenet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ux6IBMqGelY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3_oAom1GqLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzI3OWEELzcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "\n",
        "  # Initialize these variables which will be set in this if statement. Each of these\n",
        "  #   variables is model specific.\n",
        "  model_ft = None\n",
        "  input_size = 0\n",
        "\n",
        "  if model_name == \"resnet\":\n",
        "      \"\"\" Resnet18\n",
        "      \"\"\"\n",
        "      model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      num_ftrs = model_ft.fc.in_features\n",
        "      model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "      input_size = 224\n",
        "\n",
        "  elif model_name == \"alexnet\":\n",
        "      \"\"\" Alexnet\n",
        "      \"\"\"\n",
        "      model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      num_ftrs = model_ft.classifier[6].in_features\n",
        "      model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "      input_size = 224\n",
        "\n",
        "  elif model_name == \"vgg\":\n",
        "      \"\"\" VGG11_bn\n",
        "      \"\"\"\n",
        "      model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      num_ftrs = model_ft.classifier[6].in_features\n",
        "      model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "      input_size = 224\n",
        "\n",
        "  elif model_name == \"squeezenet\":\n",
        "      \"\"\" Squeezenet\n",
        "      \"\"\"\n",
        "      model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "      model_ft.num_classes = num_classes\n",
        "      input_size = 224\n",
        "\n",
        "  elif model_name == \"densenet\":\n",
        "      \"\"\" Densenet\n",
        "      \"\"\"\n",
        "      model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      num_ftrs = model_ft.classifier.in_features\n",
        "      model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
        "      input_size = 224\n",
        "\n",
        "  elif model_name == \"inception\":\n",
        "      \"\"\" Inception v3 \n",
        "      Be careful, expects (299,299) sized images and has auxiliary output\n",
        "      \"\"\"\n",
        "      model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "      set_parameter_requires_grad(model_ft, feature_extract)\n",
        "      # Handle the auxilary net\n",
        "      num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "      model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "      # Handle the primary net\n",
        "      num_ftrs = model_ft.fc.in_features\n",
        "      model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "      input_size = 299\n",
        " \n",
        "  elif model_name == \"mobilenet_v2\":\n",
        "       model_ft = models.mobilenet_v2(pretrained=use_pretrained)\n",
        "       set_parameter_requires_grad(model_ft,feature_extract)\n",
        "       input_size = 224\n",
        "\n",
        "  else:\n",
        "      print(\"Invalid model name, exiting...\")\n",
        "      exit()\n",
        "\n",
        "  return model_ft, input_size"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hTWXPHU2w7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "a0febde1290944799d7e67f541ab1687",
            "8ddf185cb87b42c4ace57d9213b14275",
            "bf3f45bfca53459cad3800ee7e7a0845",
            "df25a1746ed3408f9d023f542c77f8bd",
            "e6efa8cec8b44631b96e89fef9e07cb4",
            "c6a81007195e433bb345fa7c9785832e",
            "77e71df6af6b4ea2af49dca80830a917",
            "4cb13cbfad7545508fafa2dae8e80e6c"
          ]
        },
        "outputId": "b313b19e-5953-4d52-84e2-e7767c683390"
      },
      "source": [
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /root/.cache/torch/checkpoints/squeezenet1_0-a815701f.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0febde1290944799d7e67f541ab1687",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5017600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSc6sArHG-V7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f0ea6812-476e-4707-bcb4-72c7e5921ca0"
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "print(len(image_datasets['train']))\n",
        "print(len(image_datasets['val']))\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "raw_train_dataiter = iter(dataloaders_dict['train'])\n",
        "val_train_dataiter = iter(dataloaders_dict['val'])\n",
        "\n",
        "train_images = raw_train_dataiter.next()\n",
        "val_images = val_train_dataiter.next()\n",
        "print(train_images[0].shape)\n",
        "print(val_images[0].shape)\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n",
            "244\n",
            "153\n",
            "torch.Size([8, 3, 224, 224])\n",
            "torch.Size([8, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKsCJEfhjBHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc563125-2816-460a-af15-8fba5fd2a301"
      },
      "source": [
        "print(model_ft)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSp-04rNHDb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e24036c7-1124-415b-96af-1a392a880a32"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "# Observe that all parameters are being optimized\n",
        "#inception\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.1.weight\n",
            "\t classifier.1.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-i2-H3CHIZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ad9c0dc-3eec-4f14-a87c-dbec26bfb002"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.5002 Acc: 0.7377\n",
            "val Loss: 0.3732 Acc: 0.8693\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.3231 Acc: 0.8689\n",
            "val Loss: 0.3367 Acc: 0.9020\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.2293 Acc: 0.8975\n",
            "val Loss: 0.3269 Acc: 0.9020\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.2655 Acc: 0.8730\n",
            "val Loss: 0.3753 Acc: 0.8954\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.2353 Acc: 0.8934\n",
            "val Loss: 0.4129 Acc: 0.8889\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.1568 Acc: 0.9385\n",
            "val Loss: 0.3197 Acc: 0.9085\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.1898 Acc: 0.9221\n",
            "val Loss: 0.3132 Acc: 0.9346\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.1789 Acc: 0.9221\n",
            "val Loss: 0.3587 Acc: 0.9216\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.1775 Acc: 0.9221\n",
            "val Loss: 0.4071 Acc: 0.9085\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.1742 Acc: 0.9262\n",
            "val Loss: 0.3679 Acc: 0.9150\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.1238 Acc: 0.9467\n",
            "val Loss: 0.3382 Acc: 0.9281\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.1205 Acc: 0.9590\n",
            "val Loss: 0.3685 Acc: 0.9281\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.1208 Acc: 0.9508\n",
            "val Loss: 0.3885 Acc: 0.9412\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.1570 Acc: 0.9467\n",
            "val Loss: 0.3755 Acc: 0.9281\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.1286 Acc: 0.9549\n",
            "val Loss: 0.3820 Acc: 0.9281\n",
            "\n",
            "Training complete in 1m 22s\n",
            "Best val Acc: 0.941176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZJ--yiRHO1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0180a5d1-70de-4e81-e841-92f9a4b546bd"
      },
      "source": [
        "# Initialize the non-pretrained version of the model used for this run\n",
        "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "scratch_model = scratch_model.to(device)\n",
        "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
        "scratch_criterion = nn.CrossEntropyLoss()\n",
        "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
        "\n",
        "# Plot the training curves of validation accuracy vs. number\n",
        "#  of training epochs for the transfer learning method and\n",
        "#  the model trained from scratch\n",
        "ohist = []\n",
        "shist = []\n",
        "\n",
        "ohist = [h.cpu().numpy() for h in hist]\n",
        "shist = [h.cpu().numpy() for h in scratch_hist]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
        "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.6973 Acc: 0.4549\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.4590\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.4959\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6924 Acc: 0.5164\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.6924 Acc: 0.5082\n",
            "val Loss: 0.6931 Acc: 0.4641\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.6910 Acc: 0.5369\n",
            "val Loss: 0.6930 Acc: 0.4837\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.6841 Acc: 0.5410\n",
            "val Loss: 0.6676 Acc: 0.5752\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.7035 Acc: 0.5451\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.6909 Acc: 0.5041\n",
            "val Loss: 0.6918 Acc: 0.4575\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.6895 Acc: 0.5041\n",
            "val Loss: 0.6917 Acc: 0.4575\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.6825 Acc: 0.5041\n",
            "val Loss: 0.7412 Acc: 0.4575\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.6777 Acc: 0.5041\n",
            "val Loss: 0.6919 Acc: 0.4575\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.6813 Acc: 0.5041\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5410\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5205\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Training complete in 1m 10s\n",
            "Best val Acc: 0.575163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
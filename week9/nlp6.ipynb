{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJqdMLK97FtihqQuzKZozd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "150a796f2daa4cf78675e39532e83d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1442a90d459b493f866ec4976c0b07e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d1baf808c58482ebe1a30cdcb06078c",
              "IPY_MODEL_8a61ebdcc3184e5aaf555de5da074016"
            ]
          }
        },
        "1442a90d459b493f866ec4976c0b07e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d1baf808c58482ebe1a30cdcb06078c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8f8e259fb15415aa169325dc320979d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fff61b74e5c4f1a96a1d336c7d1b87a"
          }
        },
        "8a61ebdcc3184e5aaf555de5da074016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0229c3d6de704739a65a3644ceeec986",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 587kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a492f6a363764d01af4bf33781d30036"
          }
        },
        "f8f8e259fb15415aa169325dc320979d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fff61b74e5c4f1a96a1d336c7d1b87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0229c3d6de704739a65a3644ceeec986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a492f6a363764d01af4bf33781d30036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "089adae3fb9d49b98562b1b9a03cd65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bb84a31f4994a12b38a17c1d555acbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0b31b2f52ab41208a9a23cd8b449284",
              "IPY_MODEL_20c1007fa2b24dbf847de086dfa60b09"
            ]
          }
        },
        "7bb84a31f4994a12b38a17c1d555acbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0b31b2f52ab41208a9a23cd8b449284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ea1366ff16541d0bdbeec1d17aec068",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c017409a896143379e29edd876a92cfb"
          }
        },
        "20c1007fa2b24dbf847de086dfa60b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93eb75d5470d4bbdaf0eab6b9d32718d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 884B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd62c63fa90f4f54aa9c1e84fb8b5599"
          }
        },
        "2ea1366ff16541d0bdbeec1d17aec068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c017409a896143379e29edd876a92cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93eb75d5470d4bbdaf0eab6b9d32718d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd62c63fa90f4f54aa9c1e84fb8b5599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a543b3afa2e141dfa174b35e7a260cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_36c5baac2db248c5862c67a3634acd4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_033351222a3440dd80b70d29f3103828",
              "IPY_MODEL_d4ea0b14ed4244549685d687dee16a22"
            ]
          }
        },
        "36c5baac2db248c5862c67a3634acd4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "033351222a3440dd80b70d29f3103828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e7da0699ddd4c129c931685e49b409d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9c72ca574984a4ab05031d84075c60d"
          }
        },
        "d4ea0b14ed4244549685d687dee16a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d3916df65da84d63920e556d9dffe017",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [07:28&lt;00:00, 981kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad00e1ca05ed4db8a4e0f11c41ba4867"
          }
        },
        "6e7da0699ddd4c129c931685e49b409d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9c72ca574984a4ab05031d84075c60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3916df65da84d63920e556d9dffe017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad00e1ca05ed4db8a4e0f11c41ba4867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seenu-g/eva4-2/blob/master/week9/nlp6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVMrixItXMmS"
      },
      "source": [
        "** Transformers for Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpuuhv_7Jhn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a56b60-f490-414e-eb53-b8d695ba7c4e"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 13.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a83b4c8e472db01f0d8514a43b392e3ddcde16287ace6fef4a1487a24f491e2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-le8uJIeIC_2"
      },
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3zB9yZxN8yV"
      },
      "source": [
        "transformer has already been trained with a specific vocabulary, which means we need to train with the exact same vocabulary and also tokenize our data in the same way that the transformer did when it was initially trained.transformers library has tokenizers for each of the transformer models provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG-WOKl0INy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "150a796f2daa4cf78675e39532e83d90",
            "1442a90d459b493f866ec4976c0b07e6",
            "7d1baf808c58482ebe1a30cdcb06078c",
            "8a61ebdcc3184e5aaf555de5da074016",
            "f8f8e259fb15415aa169325dc320979d",
            "8fff61b74e5c4f1a96a1d336c7d1b87a",
            "0229c3d6de704739a65a3644ceeec986",
            "a492f6a363764d01af4bf33781d30036"
          ]
        },
        "outputId": "eff387c8-36e2-450b-f2c5-a6198f6d224a"
      },
      "source": [
        "# we are using the BERT model which ignores casing (i.e. will lower case every word)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "150a796f2daa4cf78675e39532e83d90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6PaajJ8IQ4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a792f62-54c3-4816-ed24-f2491cf8089e"
      },
      "source": [
        "# The tokenizer has a vocab attribute which contains the actual vocabulary and check how many tokens are in it by checking its length.\n",
        "len(tokenizer.vocab)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A-y0tZnITpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6282ede9-5c9b-4015-dbf4-2f378a1356e4"
      },
      "source": [
        "# tokenize and lower case the data in a way that is consistent with the pre-trained transformer model.\n",
        "tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
        "print(tokens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello', 'world', 'how', 'are', 'you', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZA2dly9IWPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da0f1e7-3712-44f5-ab02-a391268d90a5"
      },
      "source": [
        "# numericalize tokens using our vocabulary using tokenizer.convert_tokens_to_ids\n",
        "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(indexes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7592, 2088, 2129, 2024, 2017, 1029]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPguvpONIZXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad118471-1df9-437d-c653-73be50b7e681"
      },
      "source": [
        "# tokenizer does have a beginning of sequence and end of sequence attributes (bos_token and eos_token)\n",
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C7pXzKWId53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3904baf4-1f2c-4c02-ed12-d38968fa5296"
      },
      "source": [
        "# get the indexes of the special tokens by converting them using the vocabulary\n",
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXzSq7fZIgqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd11fac-9c77-49ee-834c-b18e280188da"
      },
      "source": [
        "# explicitly getting them from the tokenizer.\n",
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vCgT-SgIjj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0864326-b598-41eb-e77f-2e9733c22c3b"
      },
      "source": [
        "# get the maximum length of these input sizes by checking the max_model_input_sizes for the version of the transformer we want to use\n",
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "print(max_input_length)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yZiEzq8Im98"
      },
      "source": [
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOriUxylIrXt"
      },
      "source": [
        "from torchtext import data\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FadazrevIwLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4463f43f-2fb8-4de3-93cb-ed363f60cc35"
      },
      "source": [
        "# Load the data and create the validation splits\n",
        "from torchtext import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84.1M/84.1M [00:09<00:00, 9.24MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWBJ2SZtI3Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918c1804-eb56-477b-80d7-3f84d21f6fc3"
      },
      "source": [
        "# Take example and ensure that the text has already been numericalized\n",
        "print(vars(train_data.examples[6]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [1997, 2607, 1045, 2001, 3666, 1038, 2290, 1012, 1045, 3866, 1055, 2487, 1010, 1045, 4669, 2161, 1016, 1010, 2161, 1017, 2001, 7929, 1010, 1998, 3866, 1996, 2345, 2028, 1012, 8038, 2100, 1010, 2045, 2003, 1037, 6714, 1011, 2125, 2265, 999, 1045, 2134, 1005, 1056, 2113, 2055, 2023, 2012, 2035, 1010, 2028, 1997, 2026, 2814, 2409, 2033, 2055, 2023, 1012, 1045, 2001, 2428, 7568, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 3427, 1996, 2034, 1017, 4178, 1012, 1012, 1012, 2054, 1037, 3538, 1997, 29132, 999, 9454, 2611, 3689, 17037, 1012, 2045, 2003, 2053, 2671, 4349, 1012, 1012, 1012, 2092, 1010, 6684, 2151, 1012, 2012, 1996, 2203, 1997, 2296, 2792, 2057, 2064, 4608, 1037, 12185, 1997, 1037, 22330, 7811, 1012, 2008, 1005, 1055, 2035, 1012, 2040, 14977, 2023, 1029, 2106, 2027, 5630, 2008, 1996, 2279, 2265, 1005, 1055, 4539, 4378, 2097, 2022, 3801, 2104, 2324, 1029, 11771, 3412, 14652, 3331, 1010, 22653, 1010, 7743, 2075, 1012, 1012, 1012, 1998, 2070, 2062, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 2003, 2074, 6517, 2008, 2045, 2003, 2498, 2041, 2045, 2012, 1996, 2617, 2000, 3422, 1012, 2732, 5867, 9868, 1010, 1038, 2290, 2058, 1012, 1012, 1012], 'label': 'neg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh5xdfNLI-xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1670e4a-0394-4ec2-f9ea-3ca6d08892de"
      },
      "source": [
        "# use the convert_ids_to_tokens to transform these indexes back into readable tokens.\n",
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\n",
        "print(tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['of', 'course', 'i', 'was', 'watching', 'b', '##g', '.', 'i', 'loved', 's', '##1', ',', 'i', 'liked', 'season', '2', ',', 'season', '3', 'was', 'ok', ',', 'and', 'loved', 'the', 'final', 'one', '.', 'ya', '##y', ',', 'there', 'is', 'a', 'spin', '-', 'off', 'show', '!', 'i', 'didn', \"'\", 't', 'know', 'about', 'this', 'at', 'all', ',', 'one', 'of', 'my', 'friends', 'told', 'me', 'about', 'this', '.', 'i', 'was', 'really', 'excited', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'watched', 'the', 'first', '3', 'episodes', '.', '.', '.', 'what', 'a', 'piece', 'of', 'rubbish', '!', 'teenage', 'girl', 'drama', 'fest', '.', 'there', 'is', 'no', 'science', 'fiction', '.', '.', '.', 'well', ',', 'hardly', 'any', '.', 'at', 'the', 'end', 'of', 'every', 'episode', 'we', 'can', 'catch', 'a', 'glimpse', 'of', 'a', 'cy', '##lon', '.', 'that', \"'\", 's', 'all', '.', 'who', 'cares', 'this', '?', 'did', 'they', 'decide', 'that', 'the', 'next', 'show', \"'\", 's', 'target', 'audience', 'will', 'be', 'females', 'under', '18', '?', 'boring', 'religious', 'nonsense', 'talking', ',', 'moaning', ',', 'bitch', '##ing', '.', '.', '.', 'and', 'some', 'more', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'it', 'is', 'just', 'sad', 'that', 'there', 'is', 'nothing', 'out', 'there', 'at', 'the', 'moment', 'to', 'watch', '.', 'star', '##gate', 'ruined', ',', 'b', '##g', 'over', '.', '.', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCAi15v-JBat"
      },
      "source": [
        "# we still need to build the vocabulary for the labels.\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apA_cLpSJDmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24edaecd-845c-4a78-c6dd-12bd3e045c48"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f9e4bab38c8>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGdNs5vRJG_y"
      },
      "source": [
        "# use the largest batch size that we can to get best results for transformers.\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gcMDeTnL0SC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "089adae3fb9d49b98562b1b9a03cd65a",
            "7bb84a31f4994a12b38a17c1d555acbf",
            "f0b31b2f52ab41208a9a23cd8b449284",
            "20c1007fa2b24dbf847de086dfa60b09",
            "2ea1366ff16541d0bdbeec1d17aec068",
            "c017409a896143379e29edd876a92cfb",
            "93eb75d5470d4bbdaf0eab6b9d32718d",
            "bd62c63fa90f4f54aa9c1e84fb8b5599",
            "a543b3afa2e141dfa174b35e7a260cdb",
            "36c5baac2db248c5862c67a3634acd4b",
            "033351222a3440dd80b70d29f3103828",
            "d4ea0b14ed4244549685d687dee16a22",
            "6e7da0699ddd4c129c931685e49b409d",
            "c9c72ca574984a4ab05031d84075c60d",
            "d3916df65da84d63920e556d9dffe017",
            "ad00e1ca05ed4db8a4e0f11c41ba4867"
          ]
        },
        "outputId": "178d674e-34d8-4a0c-9879-4605d61706eb"
      },
      "source": [
        "# load the pre-trained model,\n",
        "from transformers import BertTokenizer, BertModel\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "089adae3fb9d49b98562b1b9a03cd65a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a543b3afa2e141dfa174b35e7a260cdb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvUNFXdSL6Xo"
      },
      "source": [
        "import torch.nn as nn\n",
        "# Instead of using an embedding layer to get embeddings for our text, we'll be using the pre-trained transformer model. \n",
        "# These embeddings will then be fed into a GRU to produce a prediction for the sentiment of the input sentence. \n",
        "# We get the embedding dimension size (called the hidden_size) from the transformer via its config attribute.\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()    \n",
        "        self.bert = bert\n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]       \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        #output = [batch size, out dim]\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvsdVonhL91a"
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24wGweDnMBFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42211476-912f-495e-c3d2-6f89ba4f882a"
      },
      "source": [
        "# check how many parameters the model \n",
        "#  Our standard models have under 5M, but this one has 112M! \n",
        "#  Luckily, 110M of these parameters are from the transformer and we will not be training those.\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 112,241,409 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLHMZhMsMH17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31bbf5ed-44eb-46ed-b8c3-591939252cbc"
      },
      "source": [
        "# In order to freeze paramers (not train them) we need to set their requires_grad attribute to False. \n",
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,759,169 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddqbmhUuMS09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0dcb1e-aeb6-42d1-afe9-61c6b23437cc"
      },
      "source": [
        "#  double check the names of the trainable parameters, ensuring they make sense. \n",
        "# they are all the parameters of the GRU (rnn) and the linear layer (out)\n",
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-B29xbWO3nl"
      },
      "source": [
        "# we define our optimizer and criterion (loss function).\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# Place the model and criterion onto the GPU (if available)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7DH9PSiPBJl"
      },
      "source": [
        "# calculating accuracy\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "  \n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0  \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "# calculating how long a training/evaluation epoch takes.\n",
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-ZLLAjYPY3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639ad62f-3007-4ab3-ebe5-564d77132e26"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.518 | Train Acc: 73.19%\n",
            "\t Val. Loss: 0.285 |  Val. Acc: 88.56%\n",
            "Epoch: 02 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.290 | Train Acc: 88.19%\n",
            "\t Val. Loss: 0.238 |  Val. Acc: 90.39%\n",
            "Epoch: 03 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.241 | Train Acc: 90.45%\n",
            "\t Val. Loss: 0.252 |  Val. Acc: 89.63%\n",
            "Epoch: 04 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.212 | Train Acc: 91.77%\n",
            "\t Val. Loss: 0.217 |  Val. Acc: 91.65%\n",
            "Epoch: 05 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.188 | Train Acc: 92.70%\n",
            "\t Val. Loss: 0.206 |  Val. Acc: 92.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n1j8omAPfwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcb63b6-5c23-4616-bf47-d6d7553eac9e"
      },
      "source": [
        "# load up  parameters that gave us  best validation loss and try  on the test set \n",
        "model.load_state_dict(torch.load('tut6-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.197 | Test Acc: 92.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNkeFQDwPiUG"
      },
      "source": [
        "# use  model to test sentiment of some sequences. We tokenize input sequence, trim it down to te maximum length, \n",
        "# add  special tokens to either side, convert it to a tensor, add a fake batch dimension and then pass it through our model.\n",
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PUpcL1fPmk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b592086-f9e6-43bd-dc26-df8c93f17867"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is terrible\")\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02194758877158165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo3WxCzUPovy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b53f4f-9630-47ed-fd6c-824d8fa623cb"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is great\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9530491232872009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPR3iEgQyLZDU2aSfN4dfpc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seenu-g/eva4-2/blob/master/week9/nlp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OV_dtD4Or7O"
      },
      "source": [
        "1 - Simple Sentiment Analysis¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-LHKE-kwBTl"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvMhv6-Twfvg",
        "outputId": "ac8e7a3b-6995-4faa-d477-4fc2ab3d86bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:05<00:00, 14.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB4WNwPLwjdD",
        "outputId": "dc7ce4c0-0169-423d-e8c9-13097acba7e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3w046XCxCbX",
        "outputId": "eb8f6470-718a-475b-b42e-517a17ab538b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['This', 'film', 'opened', 'to', 'poor', 'showings', 'in', 'the', 'first', 'few', 'weeks', '.', 'Then', 'Meena', 'Kumari', 'died', 'and', 'it', 'just', 'brought', 'the', 'crowds', 'rolling', 'in', '.', 'Songs', 'on', 'All', 'India', 'Radio', ',', 'especially', 'Inhi', 'LogoN', 'ne', 'were', 'played', 'so', 'often', 'that', 'I', 'was', 'sick', 'of', 'them', 'at', 'the', 'time', ',', 'despite', 'recognising', 'their', 'beauty', '!', '<', 'br', '/><br', '/>Yes', ',', 'it', 'did', 'take', 'all', 'those', 'years', 'to', 'make', '.', 'This', 'was', 'because', 'the', 'marriage', 'was', 'a', 'very', 'unhappy', 'one', 'and', 'Kamal', 'Amrohi', 'also', 'had', 'difficulty', 'finding', 'the', 'money', 'to', 'make', 'the', 'film', ';', 'looking', 'at', 'the', 'sumptous', 'sets', 'and', 'costumes', ',', 'not', 'surprising', '!', '!', 'Not', 'only', 'does', 'Meena', 'Kumari', 'age', 'and', 'fall', 'ill', 'but', 'listen', 'carefully', 'to', 'Lata', \"'s\", 'voice', '.', 'Inhi', 'logoN', 'ne', 'has', 'her', '50', \"'s\", 'younger', 'voice', 'while', 'songs', 'that', 'were', 're', '-', 'recorded', 'like', 'Chalo', 'dildar', 'chalo', 'show', 'clear', 'development', '.', 'I', 'only', 'wish', 'someone', 'would', 'find', 'the', 'Ghulam', 'Mohammad', 'songs', 'that', 'were', \"n't\", 'included', 'in', 'the', 'film', ',', 'because', 'of', 'changing', 'fashions', 'that', 'called', 'for', 'fewer', 'though', 'slightly', 'songs', 'and', 'publish', 'them', '.', 'Lata', 'in', 'a', 'recent', 'interview', '(', '2007', ')', 'rated', 'Ghulam', 'Mohammad', 'as', 'one', 'of', 'the', 'best', 'composers', 'she', 'had', 'ever', 'worked', 'with', ',', 'apart', 'from', 'Madan', 'Mohan', '(', 'a', 'great', 'personal', 'friend', ')', '.', 'Notice', 'also', 'that', 'you', 'hardly', 'see', 'the', 'actors', 'at', 'all', 'in', 'the', 'Chalo', 'dildar', 'songs', ',', 'very', 'unusual', '.', 'There', 'is', 'only', 'a', 'brief', 'shot', 'of', 'Raj', 'Kumar', 'from', 'the', 'middle', 'distance', 'and', 'you', 'only', 'see', 'the', 'back', 'of', 'the', 'supposed', 'Meena', 'Kumari', '.', 'Kamal', 'Amrohi', 'made', 'a', 'virtue', 'out', 'of', 'necessity', 'and', 'focused', 'on', 'the', 'stars', 'and', 'moon', '.', 'Any', 'other', 'film', ',', 'this', 'song', 'would', 'have', 'had', 'close', '-', 'ups', 'of', 'both', 'of', 'them.<br', '/><br', '/>As', 'for', 'this', 'being', 'the', 'finest', 'film', 'ever', ',', 'I', 'would', 'beg', 'to', 'differ', '.', 'It', 'means', 'you', 'have', 'missed', 'a', 'lot', 'of', 'Indian', 'cinema', ',', 'in', 'no', 'particular', 'order', ',', 'films', 'like', 'Barsaat', '(', 'old', ')', ',', 'Devdas', '(', 'older', 'versions', ')', ',', 'Bandini', ',', 'Do', 'Bigha', 'Zameen', ',', 'Garam', 'Hava', ',', 'Dastak', ',', 'Guddi', ',', 'Aan', ',', 'Pyasa', ',', 'Kagaz', 'ke', 'Phool', ',', 'Sahib', 'Bibi', 'aur', 'Ghulam', ',', 'Kabuliwallah', ',', 'Abhimaan', ',', 'Guide', ',', 'Sujatha', ',', 'Bombay', 'ka', 'Babu', ',', 'Daag', ',', 'Parineeta', '(', 'old', ')', ',', 'Umrao', 'Jaan', ',', 'etc', '.', 'etc', '.', 'And', 'if', 'you', 'valued', 'music', 'more', 'than', 'story', 'the', 'list', 'would', 'simply', 'grow', 'with', 'beautiful', 'scores', 'from', 'Barsat', 'Ki', 'Raat', 'to', 'Naya', 'Daur', ',', 'Teesri', 'Manzil', ',', 'Mahal', ',', 'Aag', ',', 'Jugnu', ',', 'Anand', ',', 'Mera', 'Naam', 'Joker', ':', 'the', 'list', 'is', 'really', 'endless!<br', '/><br', '/>So', 'enjoy', 'Pakeezah', 'but', 'do', \"n't\", 'miss', 'out', 'on', 'any', 'of', 'the', 'above', '...'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W3peQN7xHnI",
        "outputId": "6b909295-1890-49c7-ab0e-219293c065ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMGxUTmxUi5",
        "outputId": "c72cb3dd-bfab-48a0-f4f5-708ee7f428b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N35Lx-Cfxb7b",
        "outputId": "f48aaf00-31e2-473c-f1f2-440afa6b8125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 203050), (',', 192823), ('.', 165678), ('and', 109957), ('a', 109264), ('of', 100930), ('to', 93500), ('is', 76092), ('in', 61480), ('I', 53837), ('it', 53663), ('that', 49375), ('\"', 44101), (\"'s\", 43869), ('this', 42366), ('-', 37187), ('/><br', 35546), ('was', 35027), ('as', 30323), ('with', 29969)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOD6F-QOxe_C",
        "outputId": "d8cc57a5-4e9b-4fea-f559-6625481d2e05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZH5Okwqxeji",
        "outputId": "f2ddf937-6e9e-4281-9ce4-e3e32995cf17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f18f4876f28>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywq4X5dtxlyk"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyNsawRhxmJk"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "795GfE6PxuO9"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0r9B8iSx5Ie",
        "outputId": "77ed0071-62bf-4ebc-c4a0-9d736b4a2099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqCzslVAx9pG"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLs5SH_lyFy2"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCC9Jv-0yH3W"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw00wJeryOs2"
      },
      "source": [
        "  def evaluate(model, iterator, criterion):\n",
        "  \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            if (count <5):\n",
        "              print(batch.text)\n",
        "              count+=1\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6neozaeyTKn"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTDh1M1oyXZ3",
        "outputId": "4b2b05ce-a9c2-450b-acb7-077256144962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  66,   66,  612,  ...,   11,  238, 7734],\n",
            "        [  24,   19,    2,  ...,   57,  306,    0],\n",
            "        [ 318,    6, 2224,  ...,   30,  148,    9],\n",
            "        ...,\n",
            "        [  10,   16,    7,  ...,    1,    1,    1],\n",
            "        [1823,   23,  323,  ...,    1,    1,    1],\n",
            "        [   4,    4,   39,  ...,    1,    1,    1]])\n",
            "tensor([[   25, 12028,    66,  ...,    56,   782,   127],\n",
            "        [    0,     5,    23,  ...,    15, 11633,     6],\n",
            "        [ 8734,  2390,    99,  ...,     6, 12421,     0],\n",
            "        ...,\n",
            "        [  893,  8364, 21473,  ...,     1,     1,     1],\n",
            "        [  672,  3683,  1065,  ...,     1,     1,     1],\n",
            "        [    4,     4,    58,  ...,     1,     1,     1]])\n",
            "tensor([[  66,   66,  612,  ...,   11, 7953,   11],\n",
            "        [   9,   23,    6,  ...,  176,    3,   19],\n",
            "        [ 439,    9,  997,  ...,    6,   49,   62],\n",
            "        ...,\n",
            "        [ 956,    5, 2276,  ...,    1,    1,    1],\n",
            "        [6107, 5935,    4,  ...,    1,    1,    1],\n",
            "        [   0,    4,    1,  ...,    1,    1,    1]])\n",
            "tensor([[  25,  238,   66,  ..., 1761,  171,  155],\n",
            "        [  23,  267,    9,  ...,  132,   31,  176],\n",
            "        [ 440,  266,   65,  ...,    4,  143,   33],\n",
            "        ...,\n",
            "        [ 236,   18,   96,  ...,    1,    1,    1],\n",
            "        [  99,  166,   57,  ...,    1,    1,    1],\n",
            "        [  39,  555,    4,  ...,    1,    1,    1]])\n",
            "tensor([[ 698,   11, 1131,  ...,   66,   11,   66],\n",
            "        [ 147,   34,  794,  ...,   24,  119,   23],\n",
            "        [ 292,  126,   46,  ...,  559, 8689,   76],\n",
            "        ...,\n",
            "        [2794,   39,  364,  ...,    1,    1,    1],\n",
            "        [  12,   39,   39,  ...,    1,    1,    1],\n",
            "        [   4,   39, 2762,  ...,    1,    1,    1]])\n",
            "Epoch: 01 | Epoch Time: 15m 12s\n",
            "\tTrain Loss: 0.694 | Train Acc: 50.35%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.65%\n",
            "tensor([[  66,   66,  612,  ...,   11,  238, 7734],\n",
            "        [  24,   19,    2,  ...,   57,  306,    0],\n",
            "        [ 318,    6, 2224,  ...,   30,  148,    9],\n",
            "        ...,\n",
            "        [  10,   16,    7,  ...,    1,    1,    1],\n",
            "        [1823,   23,  323,  ...,    1,    1,    1],\n",
            "        [   4,    4,   39,  ...,    1,    1,    1]])\n",
            "tensor([[   25, 12028,    66,  ...,    56,   782,   127],\n",
            "        [    0,     5,    23,  ...,    15, 11633,     6],\n",
            "        [ 8734,  2390,    99,  ...,     6, 12421,     0],\n",
            "        ...,\n",
            "        [  893,  8364, 21473,  ...,     1,     1,     1],\n",
            "        [  672,  3683,  1065,  ...,     1,     1,     1],\n",
            "        [    4,     4,    58,  ...,     1,     1,     1]])\n",
            "tensor([[  66,   66,  612,  ...,   11, 7953,   11],\n",
            "        [   9,   23,    6,  ...,  176,    3,   19],\n",
            "        [ 439,    9,  997,  ...,    6,   49,   62],\n",
            "        ...,\n",
            "        [ 956,    5, 2276,  ...,    1,    1,    1],\n",
            "        [6107, 5935,    4,  ...,    1,    1,    1],\n",
            "        [   0,    4,    1,  ...,    1,    1,    1]])\n",
            "tensor([[  25,  238,   66,  ..., 1761,  171,  155],\n",
            "        [  23,  267,    9,  ...,  132,   31,  176],\n",
            "        [ 440,  266,   65,  ...,    4,  143,   33],\n",
            "        ...,\n",
            "        [ 236,   18,   96,  ...,    1,    1,    1],\n",
            "        [  99,  166,   57,  ...,    1,    1,    1],\n",
            "        [  39,  555,    4,  ...,    1,    1,    1]])\n",
            "tensor([[ 698,   11, 1131,  ...,   66,   11,   66],\n",
            "        [ 147,   34,  794,  ...,   24,  119,   23],\n",
            "        [ 292,  126,   46,  ...,  559, 8689,   76],\n",
            "        ...,\n",
            "        [2794,   39,  364,  ...,    1,    1,    1],\n",
            "        [  12,   39,   39,  ...,    1,    1,    1],\n",
            "        [   4,   39, 2762,  ...,    1,    1,    1]])\n",
            "Epoch: 02 | Epoch Time: 15m 15s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.88%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.89%\n",
            "tensor([[  66,   66,  612,  ...,   11,  238, 7734],\n",
            "        [  24,   19,    2,  ...,   57,  306,    0],\n",
            "        [ 318,    6, 2224,  ...,   30,  148,    9],\n",
            "        ...,\n",
            "        [  10,   16,    7,  ...,    1,    1,    1],\n",
            "        [1823,   23,  323,  ...,    1,    1,    1],\n",
            "        [   4,    4,   39,  ...,    1,    1,    1]])\n",
            "tensor([[   25, 12028,    66,  ...,    56,   782,   127],\n",
            "        [    0,     5,    23,  ...,    15, 11633,     6],\n",
            "        [ 8734,  2390,    99,  ...,     6, 12421,     0],\n",
            "        ...,\n",
            "        [  893,  8364, 21473,  ...,     1,     1,     1],\n",
            "        [  672,  3683,  1065,  ...,     1,     1,     1],\n",
            "        [    4,     4,    58,  ...,     1,     1,     1]])\n",
            "tensor([[  66,   66,  612,  ...,   11, 7953,   11],\n",
            "        [   9,   23,    6,  ...,  176,    3,   19],\n",
            "        [ 439,    9,  997,  ...,    6,   49,   62],\n",
            "        ...,\n",
            "        [ 956,    5, 2276,  ...,    1,    1,    1],\n",
            "        [6107, 5935,    4,  ...,    1,    1,    1],\n",
            "        [   0,    4,    1,  ...,    1,    1,    1]])\n",
            "tensor([[  25,  238,   66,  ..., 1761,  171,  155],\n",
            "        [  23,  267,    9,  ...,  132,   31,  176],\n",
            "        [ 440,  266,   65,  ...,    4,  143,   33],\n",
            "        ...,\n",
            "        [ 236,   18,   96,  ...,    1,    1,    1],\n",
            "        [  99,  166,   57,  ...,    1,    1,    1],\n",
            "        [  39,  555,    4,  ...,    1,    1,    1]])\n",
            "tensor([[ 698,   11, 1131,  ...,   66,   11,   66],\n",
            "        [ 147,   34,  794,  ...,   24,  119,   23],\n",
            "        [ 292,  126,   46,  ...,  559, 8689,   76],\n",
            "        ...,\n",
            "        [2794,   39,  364,  ...,    1,    1,    1],\n",
            "        [  12,   39,   39,  ...,    1,    1,    1],\n",
            "        [   4,   39, 2762,  ...,    1,    1,    1]])\n",
            "Epoch: 03 | Epoch Time: 15m 9s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.13%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.30%\n",
            "tensor([[  66,   66,  612,  ...,   11,  238, 7734],\n",
            "        [  24,   19,    2,  ...,   57,  306,    0],\n",
            "        [ 318,    6, 2224,  ...,   30,  148,    9],\n",
            "        ...,\n",
            "        [  10,   16,    7,  ...,    1,    1,    1],\n",
            "        [1823,   23,  323,  ...,    1,    1,    1],\n",
            "        [   4,    4,   39,  ...,    1,    1,    1]])\n",
            "tensor([[   25, 12028,    66,  ...,    56,   782,   127],\n",
            "        [    0,     5,    23,  ...,    15, 11633,     6],\n",
            "        [ 8734,  2390,    99,  ...,     6, 12421,     0],\n",
            "        ...,\n",
            "        [  893,  8364, 21473,  ...,     1,     1,     1],\n",
            "        [  672,  3683,  1065,  ...,     1,     1,     1],\n",
            "        [    4,     4,    58,  ...,     1,     1,     1]])\n",
            "tensor([[  66,   66,  612,  ...,   11, 7953,   11],\n",
            "        [   9,   23,    6,  ...,  176,    3,   19],\n",
            "        [ 439,    9,  997,  ...,    6,   49,   62],\n",
            "        ...,\n",
            "        [ 956,    5, 2276,  ...,    1,    1,    1],\n",
            "        [6107, 5935,    4,  ...,    1,    1,    1],\n",
            "        [   0,    4,    1,  ...,    1,    1,    1]])\n",
            "tensor([[  25,  238,   66,  ..., 1761,  171,  155],\n",
            "        [  23,  267,    9,  ...,  132,   31,  176],\n",
            "        [ 440,  266,   65,  ...,    4,  143,   33],\n",
            "        ...,\n",
            "        [ 236,   18,   96,  ...,    1,    1,    1],\n",
            "        [  99,  166,   57,  ...,    1,    1,    1],\n",
            "        [  39,  555,    4,  ...,    1,    1,    1]])\n",
            "tensor([[ 698,   11, 1131,  ...,   66,   11,   66],\n",
            "        [ 147,   34,  794,  ...,   24,  119,   23],\n",
            "        [ 292,  126,   46,  ...,  559, 8689,   76],\n",
            "        ...,\n",
            "        [2794,   39,  364,  ...,    1,    1,    1],\n",
            "        [  12,   39,   39,  ...,    1,    1,    1],\n",
            "        [   4,   39, 2762,  ...,    1,    1,    1]])\n",
            "Epoch: 04 | Epoch Time: 15m 7s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.99%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.41%\n",
            "tensor([[  66,   66,  612,  ...,   11,  238, 7734],\n",
            "        [  24,   19,    2,  ...,   57,  306,    0],\n",
            "        [ 318,    6, 2224,  ...,   30,  148,    9],\n",
            "        ...,\n",
            "        [  10,   16,    7,  ...,    1,    1,    1],\n",
            "        [1823,   23,  323,  ...,    1,    1,    1],\n",
            "        [   4,    4,   39,  ...,    1,    1,    1]])\n",
            "tensor([[   25, 12028,    66,  ...,    56,   782,   127],\n",
            "        [    0,     5,    23,  ...,    15, 11633,     6],\n",
            "        [ 8734,  2390,    99,  ...,     6, 12421,     0],\n",
            "        ...,\n",
            "        [  893,  8364, 21473,  ...,     1,     1,     1],\n",
            "        [  672,  3683,  1065,  ...,     1,     1,     1],\n",
            "        [    4,     4,    58,  ...,     1,     1,     1]])\n",
            "tensor([[  66,   66,  612,  ...,   11, 7953,   11],\n",
            "        [   9,   23,    6,  ...,  176,    3,   19],\n",
            "        [ 439,    9,  997,  ...,    6,   49,   62],\n",
            "        ...,\n",
            "        [ 956,    5, 2276,  ...,    1,    1,    1],\n",
            "        [6107, 5935,    4,  ...,    1,    1,    1],\n",
            "        [   0,    4,    1,  ...,    1,    1,    1]])\n",
            "tensor([[  25,  238,   66,  ..., 1761,  171,  155],\n",
            "        [  23,  267,    9,  ...,  132,   31,  176],\n",
            "        [ 440,  266,   65,  ...,    4,  143,   33],\n",
            "        ...,\n",
            "        [ 236,   18,   96,  ...,    1,    1,    1],\n",
            "        [  99,  166,   57,  ...,    1,    1,    1],\n",
            "        [  39,  555,    4,  ...,    1,    1,    1]])\n",
            "tensor([[ 698,   11, 1131,  ...,   66,   11,   66],\n",
            "        [ 147,   34,  794,  ...,   24,  119,   23],\n",
            "        [ 292,  126,   46,  ...,  559, 8689,   76],\n",
            "        ...,\n",
            "        [2794,   39,  364,  ...,    1,    1,    1],\n",
            "        [  12,   39,   39,  ...,    1,    1,    1],\n",
            "        [   4,   39, 2762,  ...,    1,    1,    1]])\n",
            "Epoch: 05 | Epoch Time: 15m 9s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.31%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uto2p0qgybTA",
        "outputId": "84955f50-164d-43b0-d943-0a14c5933874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  469,    11,    11,  ...,  6738,  7783,     0],\n",
            "        [    3,    75,   161,  ...,     5,     2,     0],\n",
            "        [   16,     8,   126,  ...,   771,   297,     0],\n",
            "        ...,\n",
            "        [10829,    74,  2311,  ...,     1,     1,     1],\n",
            "        [    4,   732,   428,  ...,     1,     1,     1],\n",
            "        [   14,     4,     4,  ...,     1,     1,     1]])\n",
            "tensor([[   66,    25,   324,  ...,   149,    25,   261],\n",
            "        [   23,   286,     2,  ...,    76,  6220,     6],\n",
            "        [   19,    17, 14006,  ...,   834, 22417,  4736],\n",
            "        ...,\n",
            "        [ 5734,    80,   105,  ...,     1,     1,     1],\n",
            "        [ 1419,  2745,    23,  ...,     1,     1,     1],\n",
            "        [   39,     4,     4,  ...,     1,     1,     1]])\n",
            "tensor([[ 1535,    25,    25,  ...,  4878,   469,   332],\n",
            "        [  199,   672,  1260,  ...,   630,     3, 18184],\n",
            "        [   14,   332,   344,  ...,     7,    11,   230],\n",
            "        ...,\n",
            "        [  472,     9,  2180,  ...,     1,     1,     1],\n",
            "        [  635, 19167,     4,  ...,     1,     1,     1],\n",
            "        [    4,     4,    29,  ...,     1,     1,     1]])\n",
            "tensor([[   16,     0,   360,  ...,   782,    66, 14680],\n",
            "        [  116,  3029,     6,  ...,    12,     9,    24],\n",
            "        [    9,    10,    24,  ...,    15,    40,    13],\n",
            "        ...,\n",
            "        [  129, 21164,     0,  ...,     1,     1,     1],\n",
            "        [   12,     0,    15,  ...,     1,     1,     1],\n",
            "        [   39,     4,     4,  ...,     1,     1,     1]])\n",
            "tensor([[  155,    66,    56,  ...,   149,    25,    66],\n",
            "        [  272,    24,     9,  ...,   625,   144, 20226],\n",
            "        [  791,     9,     6,  ...,     4,   219,    23],\n",
            "        ...,\n",
            "        [   43,     8,    12,  ...,     4,    88,   555],\n",
            "        [ 3371,     0,    39,  ...,     1,     1,     1],\n",
            "        [    4,     4,  3537,  ...,     1,     1,     1]])\n",
            "Test Loss: 0.709 | Test Acc: 47.51%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}